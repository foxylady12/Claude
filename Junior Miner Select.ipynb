{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e3929db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Input file found: koyfin_Junior Miners.csv\n",
      "üìÖ File date: 2025-11-04 10:24:46\n",
      "Input file: G:\\My Drive\\INPUTS\\EXCEL\\Miners\\koyfin_Junior Miners.csv\n",
      "Output file will be saved to: G:\\My Drive\\OUTPUTS\\EXCEL\\Miner\\Junior_Miner_Analysis_V6_20251104_120600.xlsx\n",
      "üìÖ Timestamp: 20251104_120600\n",
      "\n",
      "‚úÖ SELECT file found: koyfin_Select Miners.csv\n",
      "   üìå Loaded 18 companies for comparison (via ISIN matching)\n",
      "   üîç Sample: UURAF, TMQ, ARA, HAS, NB...\n",
      "\n",
      "üìà Loaded 498 companies with 41 columns\n",
      "   üìä Selection Status: 17/18 SELECT companies found in data\n",
      "\n",
      "üîç Applying Data Quality Screen...\n",
      "   - 84 companies excluded for missing critical data.\n",
      "‚ö†Ô∏è Applying Collapsed Market Cap Screen...\n",
      "   - 33 companies flagged for collapsed market cap.\n",
      "   ‚úÖ 381 companies remaining for full analysis.\n",
      "\n",
      "üõ†Ô∏è Engineering and transforming features for scoring consistency...\n",
      "\n",
      "‚öôÔ∏è Scoring Model: 7 factors defined.\n",
      "üî¢ Processing 12 KPIs for scoring...\n",
      "\n",
      "‚öñÔ∏è Normalizing factor scores and calculating Total Scores...\n",
      "‚úÖ Scoring & Normalization complete for 381 companies\n",
      "\n",
      "üéØ Performing K-Means Clustering (k=3)...\n",
      "üìä Clustering Results:\n",
      "   üéØ Silhouette Score: 0.170 (Poor)\n",
      "       0: Speculative Growers (137 companies)\n",
      "       1: Stalwart Survivors (104 companies)\n",
      "       2: Investing Survivors (140 companies)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:200: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:200: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:200: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:200: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:200: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:200: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:200: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:200: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:200: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:200: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:200: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:200: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:213: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[score_col_name].fillna(3, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:213: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[score_col_name].fillna(3, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:213: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[score_col_name].fillna(3, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:213: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[score_col_name].fillna(3, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:213: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[score_col_name].fillna(3, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:213: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[score_col_name].fillna(3, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:213: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[score_col_name].fillna(3, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:213: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[score_col_name].fillna(3, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:213: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[score_col_name].fillna(3, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:213: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[score_col_name].fillna(3, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:213: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df[score_col_name].fillna(3, inplace=True)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:222: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  score_df = score_df.groupby('Stage_Proxy', group_keys=False).apply(safe_qcut_scorer_inv_pb)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:222: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  score_df = score_df.groupby('Stage_Proxy', group_keys=False).apply(safe_qcut_scorer_inv_pb)\n",
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_38872\\3974996651.py:223: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  score_df['Inv_P_B_LTM_Score'].fillna(3, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä PCA plot saved to: G:\\My Drive\\OUTPUTS\\EXCEL\\Miner\\Junior_Miner_Analysis_V6_20251104_120600_PCA_k3.png\n",
      "\n",
      "üìù Generating Tier & Cluster Profile Analysis tables...\n",
      "üìà Generating Combined Tier-Cluster 3M Return Analysis...\n",
      "\n",
      "üìä Generating Excel Output...\n",
      "‚úÖ Excel Table created successfully\n",
      "   üìå Table name: ScoringClustersTable\n",
      "   üìç Selection_Status column: Click dropdown to filter SELECT or ALL\n",
      "\n",
      "üéâ Analysis Complete!\n",
      "üìä Results saved to: G:\\My Drive\\OUTPUTS\\EXCEL\\Miner\\Junior_Miner_Analysis_V6_20251104_120600.xlsx\n",
      "üìà PCA plot saved to: G:\\My Drive\\OUTPUTS\\EXCEL\\Miner\\Junior_Miner_Analysis_V6_20251104_120600_PCA_k3.png\n",
      "\n",
      "üìã Quick Preview - Top 5 companies by Additive Rank:\n",
      " Rank_Additive  Rank_Multiplicative Ticker                                Name Selection_Status       Cluster_Name\n",
      "             1                    3    APM        Andean Precious Metals Corp.              ALL Stalwart Survivors\n",
      "             2                    1    MMY             Monument Mining Limited              ALL Stalwart Survivors\n",
      "             3                  166    MJS                 Majestic Gold Corp.              ALL Stalwart Survivors\n",
      "             4                    5    GMX      Globex Mining Enterprises Inc.              ALL Stalwart Survivors\n",
      "             5                    2    WRN Western Copper and Gold Corporation              ALL Stalwart Survivors\n",
      "\n",
      "üìã Quick Preview - Top 5 companies by Multiplicative Rank:\n",
      " Rank_Additive  Rank_Multiplicative Ticker                                Name Selection_Status       Cluster_Name\n",
      "             2                    1    MMY             Monument Mining Limited              ALL Stalwart Survivors\n",
      "             5                    2    WRN Western Copper and Gold Corporation              ALL Stalwart Survivors\n",
      "             1                    3    APM        Andean Precious Metals Corp.              ALL Stalwart Survivors\n",
      "             6                    4    ELE     Elemental Altus Royalties Corp.              ALL Stalwart Survivors\n",
      "             4                    5    GMX      Globex Mining Enterprises Inc.              ALL Stalwart Survivors\n",
      "\n",
      "üìù Analysis logged in: G:\\My Drive\\OUTPUTS\\EXCEL\\Miner\\analysis_log.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
    "\n",
    "# --- 1. SETUP: Direct File Path ---\n",
    "input_csv_path = r\"G:\\My Drive\\INPUTS\\EXCEL\\Miners\\koyfin_Junior Miners.csv\"\n",
    "\n",
    "if not os.path.exists(input_csv_path):\n",
    "    print(f\"‚ùå Error: Input file not found at: {input_csv_path}\")\n",
    "    print(f\"Please ensure the file exists at the specified location.\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(f\"‚úÖ Input file found: {os.path.basename(input_csv_path)}\")\n",
    "    print(f\"üìÖ File date: {datetime.fromtimestamp(os.path.getmtime(input_csv_path)).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_excel_name = f\"Junior_Miner_Analysis_V6_{timestamp}.xlsx\"\n",
    "output_folder = r\"G:\\My Drive\\OUTPUTS\\EXCEL\\Miner\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_excel_path = os.path.join(output_folder, output_excel_name)\n",
    "\n",
    "print(f\"Input file: {input_csv_path}\")\n",
    "print(f\"Output file will be saved to: {output_excel_path}\")\n",
    "print(f\"üìÖ Timestamp: {timestamp}\")\n",
    "\n",
    "# --- LOAD SELECT CSV FOR FILTERING (ISIN-BASED MATCHING) ---\n",
    "select_csv_path = r\"G:\\My Drive\\INPUTS\\EXCEL\\Miners\\koyfin_Select Miners.csv\"\n",
    "select_isins = set()\n",
    "select_tickers_list = []\n",
    "select_count = 0\n",
    "\n",
    "if os.path.exists(select_csv_path):\n",
    "    print(f\"\\n‚úÖ SELECT file found: {os.path.basename(select_csv_path)}\")\n",
    "    try:\n",
    "        select_df = pd.read_csv(select_csv_path)\n",
    "        select_df.columns = select_df.columns.str.strip()\n",
    "        if 'ISIN' in select_df.columns:\n",
    "            select_isins = set(select_df['ISIN'].dropna().str.strip())\n",
    "            select_tickers_list = select_df['Ticker'].dropna().str.strip().tolist()\n",
    "            select_count = len(select_isins)\n",
    "            print(f\"   üìå Loaded {select_count} companies for comparison (via ISIN matching)\")\n",
    "            if select_count > 0:\n",
    "                sample_list = ', '.join(select_tickers_list[:5])\n",
    "                print(f\"   üîç Sample: {sample_list}{'...' if select_count > 5 else ''}\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è Warning: 'ISIN' column not found in SELECT file\")\n",
    "            print(f\"   Falling back to Ticker matching...\")\n",
    "            if 'Ticker' in select_df.columns:\n",
    "                select_isins = set(select_df['Ticker'].dropna().str.strip().str.upper())\n",
    "                select_count = len(select_isins)\n",
    "                print(f\"   üìå Loaded {select_count} companies (via Ticker)\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è Neither ISIN nor Ticker column found\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Error reading SELECT file: {e}\")\n",
    "        select_isins = set()\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è SELECT file not found: {select_csv_path}\")\n",
    "    print(f\"   Proceeding without SELECT filtering\")\n",
    "    select_isins = set()\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "def human_name_clusters(profiles, factor_score_cols):\n",
    "    \"\"\"Assigns descriptive names to the three clusters.\"\"\"\n",
    "    names = {}\n",
    "    remaining_ids = list(profiles.index)\n",
    "    grower_id = profiles.loc[remaining_ids, 'RealGrowth_Checker_Score'].idxmax()\n",
    "    names[grower_id] = \"Speculative Growers\"\n",
    "    remaining_ids.remove(grower_id)\n",
    "    if profiles.loc[remaining_ids[0], 'FinancialStability_Score'] > profiles.loc[remaining_ids[1], 'FinancialStability_Score']:\n",
    "        names[remaining_ids[0]] = \"Stalwart Survivors\"\n",
    "        names[remaining_ids[1]] = \"Investing Survivors\"\n",
    "    else:\n",
    "        names[remaining_ids[1]] = \"Stalwart Survivors\"\n",
    "        names[remaining_ids[0]] = \"Investing Survivors\"\n",
    "    return names\n",
    "\n",
    "def make_pca_scatter(scaled_data, labels, output_path):\n",
    "    \"\"\"Create and save PCA scatter plot.\"\"\"\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    pca_data = pca.fit_transform(scaled_data)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(pca_data[:, 0], pca_data[:, 1], c=labels, alpha=0.7, cmap='viridis')\n",
    "    plt.xlabel(f'PCA Component 1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "    plt.ylabel(f'PCA Component 2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "    plt.title('Junior Miners ‚Äî PCA Scatter (k=3)')\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.tight_layout()\n",
    "    png_path = os.path.splitext(output_path)[0] + \"_PCA_k3.png\"\n",
    "    plt.savefig(png_path, dpi=160, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"üìä PCA plot saved to: {png_path}\")\n",
    "    return png_path\n",
    "\n",
    "# --- 2. DATA LOADING AND CLEANING ---\n",
    "df = pd.read_csv(input_csv_path)\n",
    "df.columns = df.columns.str.strip()\n",
    "print(f\"\\nüìà Loaded {len(df)} companies with {len(df.columns)} columns\")\n",
    "\n",
    "# --- ADD SELECTION_STATUS COLUMN (ISIN-BASED MATCHING) ---\n",
    "df['ISIN'] = df['ISIN'].astype(str).str.strip()\n",
    "df['Selection_Status'] = df['ISIN'].apply(\n",
    "    lambda x: \"SELECT\" if x in select_isins else \"ALL\"\n",
    ")\n",
    "select_in_universe = len(df[df['Selection_Status'] == 'SELECT'])\n",
    "if select_count > 0:\n",
    "    print(f\"   üìä Selection Status: {select_in_universe}/{select_count} SELECT companies found in data\\n\")\n",
    "\n",
    "# --- 3. DATA SCREENING PIPELINE ---\n",
    "print(\"üîç Applying Data Quality Screen...\")\n",
    "critical_kpis = [\n",
    "    'Market Cap', 'Net Debt / MKT Cap', 'cash from ops / mkt cap',\n",
    "    'CapEX V Mkt CAP (3Y AV)', 'P/B (LTM)', 'Shrs % Chg (1Y)', 'Total Return (1Y)'\n",
    "]\n",
    "check_df = df[['Ticker', 'Name'] + critical_kpis].copy()\n",
    "for col in critical_kpis:\n",
    "    check_df[col] = pd.to_numeric(check_df[col], errors='coerce')\n",
    "\n",
    "missing_data_mask = check_df[critical_kpis].isna().any(axis=1)\n",
    "data_catcher_df = df[missing_data_mask].copy()\n",
    "data_catcher_df['Reason_for_Exclusion'] = \"Missing data in one or more critical KPIs\"\n",
    "analysis_df = df[~missing_data_mask].copy()\n",
    "print(f\"   - {len(data_catcher_df)} companies excluded for missing critical data.\")\n",
    "\n",
    "print(\"‚ö†Ô∏è Applying Collapsed Market Cap Screen...\")\n",
    "mkt_cap_col = 'Market Cap'\n",
    "mkt_cap_3y_avg_col = 'Market Cap (3YAVG)'\n",
    "analysis_df[mkt_cap_col] = pd.to_numeric(analysis_df[mkt_cap_col], errors='coerce')\n",
    "analysis_df[mkt_cap_3y_avg_col] = pd.to_numeric(analysis_df[mkt_cap_3y_avg_col], errors='coerce')\n",
    "denominator = analysis_df[mkt_cap_3y_avg_col].replace(0, np.nan)\n",
    "analysis_df['Mkt_Cap_Collapse_Ratio'] = analysis_df[mkt_cap_col] / denominator\n",
    "collapse_threshold = 0.75\n",
    "collapse_mask = analysis_df['Mkt_Cap_Collapse_Ratio'] < collapse_threshold\n",
    "collapsed_cap_df = analysis_df[collapse_mask].copy()\n",
    "collapsed_cap_df['Reason_for_Exclusion'] = f\"Market Cap is less than {collapse_threshold:.0%} of its 3Y Average\"\n",
    "analysis_df = analysis_df[~collapse_mask].copy()\n",
    "print(f\"   - {len(collapsed_cap_df)} companies flagged for collapsed market cap.\")\n",
    "print(f\"   ‚úÖ {len(analysis_df)} companies remaining for full analysis.\")\n",
    "\n",
    "if analysis_df.empty:\n",
    "    print(\"\\n‚ùå ERROR: No companies remained after all screening steps!\")\n",
    "    sys.exit()\n",
    "\n",
    "# --- 4. FEATURE ENGINEERING & DATA TRANSFORMATION ---\n",
    "print(\"\\nüõ†Ô∏è Engineering and transforming features for scoring consistency...\")\n",
    "analysis_df['Abs_Capex_LTM'] = analysis_df['Capital Expenditure (LTM)'].abs()\n",
    "epsilon = 1e-6 \n",
    "analysis_df['Cash_to_Capex_Coverage'] = analysis_df['Cash/ST Investments (LTM)'] / (analysis_df['Abs_Capex_LTM'] + epsilon)\n",
    "\n",
    "metrics_to_invert = [\n",
    "    'Net Debt / MKT Cap', 'Head Office Effeciancy', 'Shrs % Chg (1Y)', 'P/B (LTM)'\n",
    "]\n",
    "for metric in metrics_to_invert:\n",
    "    new_col_name = f\"Inv_{metric.replace(' ', '_').replace('/', '_').replace('%','').replace('(','').replace(')','')}\"\n",
    "    analysis_df[new_col_name] = analysis_df[metric] * -1\n",
    "\n",
    "# --- 5. MODEL DEFINITION ---\n",
    "factor_kpis = {\n",
    "    'Survival': {'Burn in Months': {'scoring': 'custom_runway'}, 'Inv_Net_Debt___MKT_Cap': {'scoring': 'higher_is_better'}, 'Cash_to_Capex_Coverage': {'scoring': 'higher_is_better'}},\n",
    "    'InvestmentQuality': {'CapEX V Mkt CAP (3Y AV)': {'scoring': 'higher_is_better'},'Inv_Head_Office_Effeciancy': {'scoring': 'higher_is_better'}},\n",
    "    'FinancialStability': {'cash from ops / mkt cap': {'scoring': 'higher_is_better'},'Inv_Net_Debt___MKT_Cap': {'scoring': 'higher_is_better'}},\n",
    "    'ShareholderFriendliness': {'Inv_Shrs__Chg_1Y': {'scoring': 'higher_is_better'}},\n",
    "    'Valuation': {'Inv_P_B_LTM': {'scoring': 'higher_is_better'}},\n",
    "    'MarketMomentum': {'Total Return (1Y)': {'scoring': 'higher_is_better'}},\n",
    "    'RealGrowth_Checker': {'Net Property/Plant and Equip./CAGR (3Y FY)': {'scoring': 'higher_is_better'},'Total Assets/CAGR (3Y FY)': {'scoring': 'higher_is_better'},'CAPEX/CAGR (3Y TTM)': {'scoring': 'higher_is_better'}}\n",
    "}\n",
    "print(f\"\\n‚öôÔ∏è Scoring Model: {len(factor_kpis)} factors defined.\")\n",
    "\n",
    "# --- 6. SCORING ENGINE ---\n",
    "def score_runway_kpi(series):\n",
    "    scores = pd.Series(np.nan, index=series.index)\n",
    "    scores[series >= 0] = 5\n",
    "    risky_group = series[series < 0]\n",
    "    if not risky_group.empty:\n",
    "        try:\n",
    "            risky_scores = pd.qcut(risky_group.abs(), 4, labels=False, duplicates='drop') + 1\n",
    "            scores.loc[risky_group.index] = risky_scores\n",
    "        except ValueError:\n",
    "            scores.loc[risky_group.index] = 2\n",
    "    scores.fillna(3, inplace=True)\n",
    "    return scores.astype(int)\n",
    "\n",
    "score_df = analysis_df.copy()\n",
    "all_kpis = sorted(list(set(kpi for factor in factor_kpis.values() for kpi in factor)))\n",
    "print(f\"üî¢ Processing {len(all_kpis)} KPIs for scoring...\")\n",
    "\n",
    "for col in all_kpis:\n",
    "    if col in score_df.columns:\n",
    "        score_df[col] = pd.to_numeric(score_df[col], errors='coerce')\n",
    "        median_val = score_df[col].median()\n",
    "        score_df[col].fillna(median_val, inplace=True)\n",
    "\n",
    "kpis_to_score = [k for k in all_kpis if k != 'Inv_P_B_LTM']\n",
    "for kpi in kpis_to_score:\n",
    "    score_col_name = f'{kpi}_Score'\n",
    "    scoring_type = next(factor[kpi]['scoring'] for factor in factor_kpis.values() if kpi in factor)\n",
    "    try:\n",
    "        if scoring_type == 'custom_runway':\n",
    "            score_df[score_col_name] = score_runway_kpi(score_df[kpi])\n",
    "        else:\n",
    "            score_df[score_col_name] = pd.qcut(score_df[kpi], 5, labels=False, duplicates='drop') + 1\n",
    "    except ValueError:\n",
    "        score_df[score_col_name] = 3\n",
    "    score_df[score_col_name].fillna(3, inplace=True)\n",
    "\n",
    "score_df['Stage_Proxy'] = pd.qcut(score_df['cash from ops / mkt cap'], 3, labels=['Explorer', 'Developer', 'Producer'], duplicates='drop')\n",
    "def safe_qcut_scorer_inv_pb(group):\n",
    "    try:\n",
    "        group['Inv_P_B_LTM_Score'] = pd.qcut(group['Inv_P_B_LTM'], 5, labels=False, duplicates='drop') + 1\n",
    "    except ValueError:\n",
    "        group['Inv_P_B_LTM_Score'] = 3\n",
    "    return group\n",
    "score_df = score_df.groupby('Stage_Proxy', group_keys=False).apply(safe_qcut_scorer_inv_pb)\n",
    "score_df['Inv_P_B_LTM_Score'].fillna(3, inplace=True)\n",
    "\n",
    "# --- 7. FINAL CALCULATION & NORMALIZATION ---\n",
    "for factor, kpis in factor_kpis.items():\n",
    "    score_df[f'{factor}_Score_Raw'] = sum(score_df[f'{kpi}_Score'] for kpi in kpis)\n",
    "\n",
    "print(\"\\n‚öñÔ∏è Normalizing factor scores and calculating Total Scores...\")\n",
    "for factor, kpis in factor_kpis.items():\n",
    "    raw_col_name = f'{factor}_Score_Raw'\n",
    "    norm_col_name = f'{factor}_Score'\n",
    "    min_score = len(kpis) * 1\n",
    "    max_score = len(kpis) * 5\n",
    "    if (max_score - min_score) > 0:\n",
    "        score_df[norm_col_name] = (score_df[raw_col_name] - min_score) / (max_score - min_score)\n",
    "    else:\n",
    "        score_df[norm_col_name] = (score_df[raw_col_name] - 1) / 4.0\n",
    "\n",
    "factor_score_cols = [f'{f}_Score' for f in factor_kpis.keys()]\n",
    "score_df['Total_Score_Additive'] = score_df[factor_score_cols].sum(axis=1)\n",
    "score_df['Total_Score_Multiplicative'] = score_df[factor_score_cols].prod(axis=1)\n",
    "score_df['Rank_Additive'] = score_df['Total_Score_Additive'].rank(method='min', ascending=False).astype(int)\n",
    "score_df['Rank_Multiplicative'] = score_df['Total_Score_Multiplicative'].rank(method='min', ascending=False).astype(int)\n",
    "total_companies = len(score_df)\n",
    "conditions = [score_df['Rank_Additive'] <= total_companies * 0.2, score_df['Rank_Additive'] <= total_companies * 0.6]\n",
    "choices = ['Tier 1: Investigate', 'Tier 2: Monitor']\n",
    "score_df['Tier'] = np.select(conditions, choices, default='Tier 3: Caution')\n",
    "print(f\"‚úÖ Scoring & Normalization complete for {len(score_df)} companies\")\n",
    "\n",
    "# --- 8. K-MEANS CLUSTERING ANALYSIS ---\n",
    "print(f\"\\nüéØ Performing K-Means Clustering (k=3)...\")\n",
    "cluster_data = score_df[factor_score_cols]\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(cluster_data)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(scaled_data)\n",
    "score_df['Cluster'] = cluster_labels\n",
    "profiles = score_df.groupby('Cluster')[factor_score_cols].mean()\n",
    "cluster_names = human_name_clusters(profiles, factor_score_cols)\n",
    "score_df['Cluster_Name'] = score_df['Cluster'].map(cluster_names)\n",
    "sil_score = silhouette_score(scaled_data, cluster_labels)\n",
    "print(f\"üìä Clustering Results:\")\n",
    "print(f\"   üéØ Silhouette Score: {sil_score:.3f} ({'Good' if sil_score > 0.5 else 'Fair' if sil_score > 0.25 else 'Poor'})\")\n",
    "for cluster_id, name in sorted(cluster_names.items()):\n",
    "    count = len(score_df[score_df['Cluster'] == cluster_id])\n",
    "    print(f\"       {cluster_id}: {name} ({count} companies)\")\n",
    "png_path = make_pca_scatter(scaled_data, cluster_labels, output_excel_path)\n",
    "\n",
    "# --- 9. TIER & CLUSTER PROFILE ANALYSIS ---\n",
    "print(\"\\nüìù Generating Tier & Cluster Profile Analysis tables...\")\n",
    "original_kpis_to_profile = [\n",
    "    'Burn in Months','Net Debt / MKT Cap','CapEX V Mkt CAP (3Y AV)','Head Office Effeciancy',\n",
    "    'cash from ops / mkt cap','Shrs % Chg (1Y)','P/B (LTM)','Total Return (1Y)', 'Total Return (3M)',\n",
    "    'Net Property/Plant and Equip./CAGR (3Y FY)','Total Assets/CAGR (3Y FY)','CAPEX/CAGR (3Y TTM)',\n",
    "    'Cash_to_Capex_Coverage'\n",
    "]\n",
    "score_df['Total Return (3M)'] = pd.to_numeric(score_df['Total Return (3M)'], errors='coerce')\n",
    "\n",
    "percentiles_to_calc = [0.25, 0.50, 0.75]\n",
    "percentile_labels = ['25th Percentile', 'Median (50%)', '75th Percentile']\n",
    "\n",
    "def create_profile_table(df, group_col):\n",
    "    all_tables = []\n",
    "    if group_col in df.columns:\n",
    "        for group_name in sorted(df[group_col].unique()):\n",
    "            group_df = df[df[group_col] == group_name]\n",
    "            if not group_df.empty:\n",
    "                percentile_table = group_df[original_kpis_to_profile].quantile(percentiles_to_calc).reset_index(drop=True)\n",
    "                percentile_table.index = percentile_labels\n",
    "                percentile_table.reset_index(inplace=True)\n",
    "                percentile_table.rename(columns={'index': 'Percentile'}, inplace=True)\n",
    "                percentile_table[group_col] = group_name\n",
    "                all_tables.append(percentile_table)\n",
    "        \n",
    "        if all_tables:\n",
    "            summary_df = pd.concat(all_tables, ignore_index=True)\n",
    "            cols_to_order = [group_col, 'Percentile'] + [kpi for kpi in original_kpis_to_profile if kpi in summary_df.columns]\n",
    "            return summary_df[cols_to_order]\n",
    "    return pd.DataFrame()\n",
    "\n",
    "tier_percentile_summary_df = create_profile_table(score_df, 'Tier')\n",
    "cluster_percentile_summary_df = create_profile_table(score_df, 'Cluster_Name')\n",
    "\n",
    "# --- 10. COMBINED TIER-CLUSTER 3M RETURN ANALYSIS ---\n",
    "print(\"üìà Generating Combined Tier-Cluster 3M Return Analysis...\")\n",
    "score_df['Tier_Cluster_Combo'] = score_df['Tier'] + ' - ' + score_df['Cluster_Name']\n",
    "combo_return_analysis = score_df.groupby('Tier_Cluster_Combo')['Total Return (3M)'].agg(\n",
    "    Company_Count='size',\n",
    "    **{f'{int(p*100)}th_Percentile': lambda x, p=p: x.quantile(p) for p in percentiles_to_calc}\n",
    ").reset_index()\n",
    "combo_return_analysis.rename(columns={'50th_Percentile': 'Median_Return_3M'}, inplace=True)\n",
    "\n",
    "# --- 11. OUTPUT GENERATION WITH TIMESTAMP IN METADATA ---\n",
    "final_cols_order = [\n",
    "    'Rank_Additive', 'Rank_Multiplicative', 'Ticker', 'Name', 'Selection_Status',\n",
    "    'Total_Score_Additive', 'Total_Score_Multiplicative', 'Tier', 'Cluster_Name', 'Stage_Proxy'\n",
    "] + factor_score_cols\n",
    "full_results_df = score_df[final_cols_order].sort_values('Rank_Additive')\n",
    "\n",
    "full_results_df['Analysis_Date'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print(f\"\\nüìä Generating Excel Output...\")\n",
    "overview_data = pd.DataFrame({\n",
    "    \"Metric\": [\"Analysis Date\", \"Input Rows\", \"Analyzed Rows (Post-Screen)\", \"Data Catcher Rows\", \"Collapsed Cap Rows\", \"k (clusters)\", \"Silhouette Score\"],\n",
    "    \"Value\": [datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), len(df), len(analysis_df), len(data_catcher_df), len(collapsed_cap_df), 3, round(sil_score, 3)]\n",
    "})\n",
    "cluster_summary = profiles.copy()\n",
    "cluster_summary[\"Count\"] = score_df.groupby(\"Cluster\").size()\n",
    "cluster_summary[\"Cluster_Name\"] = cluster_summary.index.map(cluster_names)\n",
    "cluster_summary = cluster_summary.reset_index(drop=True).reindex(columns=[\"Cluster_Name\", \"Count\"] + factor_score_cols)\n",
    "\n",
    "def clean_sheet_name(name):\n",
    "    for ch in ['\\\\', '/', '*', '?', '[', ']', ':', '(', ')']:\n",
    "        name = name.replace(ch, '-')\n",
    "    return name[:31]\n",
    "\n",
    "cluster_sheet_names = {cluster_id: clean_sheet_name(name) for cluster_id, name in cluster_names.items()}\n",
    "\n",
    "with pd.ExcelWriter(output_excel_path, engine='openpyxl') as writer:\n",
    "    overview_data.to_excel(writer, sheet_name='Overview', index=False)\n",
    "    cluster_summary.to_excel(writer, sheet_name='Cluster Profiles', index=False)\n",
    "    full_results_df.to_excel(writer, sheet_name='Full Scoring & Clusters', index=False)\n",
    "    \n",
    "    if not data_catcher_df.empty:\n",
    "        data_catcher_df.to_excel(writer, sheet_name='Data Catcher', index=False)\n",
    "    \n",
    "    if not collapsed_cap_df.empty:\n",
    "        collapsed_cap_df.to_excel(writer, sheet_name='Collapsed Mkt Cap Flag', index=False)\n",
    "        \n",
    "    for cluster_id, name in cluster_names.items():\n",
    "        cluster_df = full_results_df[full_results_df['Cluster_Name'] == name].copy()\n",
    "        cluster_df_top = cluster_df.sort_values('Rank_Additive').head(50)\n",
    "        sheet_name = cluster_sheet_names[cluster_id]\n",
    "        cluster_df_top.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    \n",
    "    for tier_name in ['Tier 1: Investigate', 'Tier 2: Monitor', 'Tier 3: Caution']:\n",
    "        tier_df = full_results_df[full_results_df['Tier'] == tier_name]\n",
    "        sheet_name = tier_name.replace(\":\", \"\")\n",
    "        tier_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "    if not tier_percentile_summary_df.empty:\n",
    "        tier_percentile_summary_df.to_excel(writer, sheet_name='Tier Profile Analysis', index=False, header=True)\n",
    "    if not cluster_percentile_summary_df.empty:\n",
    "        cluster_percentile_summary_df.to_excel(writer, sheet_name='Cluster Profile Analysis', index=False, header=True)\n",
    "    if not combo_return_analysis.empty:\n",
    "        combo_return_analysis.to_excel(writer, sheet_name='Tier-Cluster 3M Returns', index=False, header=True)\n",
    "\n",
    "# --- CREATE EXCEL TABLE FOR FULL SCORING TAB ---\n",
    "try:\n",
    "    wb = load_workbook(output_excel_path)\n",
    "    ws = wb['Full Scoring & Clusters']\n",
    "    \n",
    "    table_ref = f\"A1:{chr(64 + len(final_cols_order))}{len(full_results_df) + 1}\"\n",
    "    tab = Table(displayName=\"ScoringClustersTable\", ref=table_ref)\n",
    "    style = TableStyleInfo(name=\"TableStyleMedium9\", showFirstColumn=False,\n",
    "                          showLastColumn=False, showRowStripes=True, showColumnStripes=False)\n",
    "    tab.tableStyleInfo = style\n",
    "    ws.add_table(tab)\n",
    "    \n",
    "    wb.save(output_excel_path)\n",
    "    print(f\"‚úÖ Excel Table created successfully\")\n",
    "    print(f\"   üìå Table name: ScoringClustersTable\")\n",
    "    print(f\"   üìç Selection_Status column: Click dropdown to filter SELECT or ALL\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Excel Table creation note: {e}\")\n",
    "    print(f\"   Data is still present - manually add table via Data ‚Üí Format as Table\")\n",
    "\n",
    "print(f\"\\nüéâ Analysis Complete!\")\n",
    "print(f\"üìä Results saved to: {output_excel_path}\")\n",
    "print(f\"üìà PCA plot saved to: {png_path}\")\n",
    "\n",
    "print(f\"\\nüìã Quick Preview - Top 5 companies by Additive Rank:\")\n",
    "preview_cols = ['Rank_Additive', 'Rank_Multiplicative', 'Ticker', 'Name', 'Selection_Status', 'Cluster_Name']\n",
    "print(full_results_df.head(5)[preview_cols].to_string(index=False))\n",
    "\n",
    "print(f\"\\nüìã Quick Preview - Top 5 companies by Multiplicative Rank:\")\n",
    "print(full_results_df.sort_values('Rank_Multiplicative').head(5)[preview_cols].to_string(index=False))\n",
    "\n",
    "log_file_path = os.path.join(output_folder, \"analysis_log.txt\")\n",
    "with open(log_file_path, 'a') as log_file:\n",
    "    log_file.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - Analysis completed: {output_excel_name}\\n\")\n",
    "print(f\"\\nüìù Analysis logged in: {log_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
